{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Crop Unmarked MRI Scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(X):\n",
    "    res = np.zeros((len(X), len(X[0]), 300, 300))\n",
    "    for p in range(len(X)):\n",
    "        for s in range(len(X[p])):\n",
    "            for i in range(106, 406):\n",
    "                res[p][s][i - 106] = X[p][s][i][106:406]\n",
    "    return res\n",
    "            \n",
    "    \n",
    "X = np.load('small_data.npy')\n",
    "X = crop(X)\n",
    "X = torch.from_numpy(X)\n",
    "X = X.to(torch.float32)\n",
    "X = [X[i-1:i] for i in range(1, len(X))]\n",
    "\n",
    "y = pd.read_csv('all_target.csv').to_numpy()\n",
    "y = torch.tensor(y)\n",
    "\n",
    "N = len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hot-encoded y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "y6 = torch.zeros(N, 6)\n",
    "y4 = torch.zeros(N, 4)\n",
    "y2 = torch.zeros(N, 2)\n",
    "for i in range(N):\n",
    "    y6[i][y[i] - 1] = 1\n",
    "    \n",
    "    if y[i] < 3:\n",
    "        y4[i][0] = 1\n",
    "        y2[i][0] = 1\n",
    "    \n",
    "    elif y[i] == 3:\n",
    "        y4[i][1] = 1\n",
    "        y2[i][0] = 1\n",
    "        \n",
    "    elif y[i] == 4:\n",
    "        y4[i][2] = 1\n",
    "        y2[i][1] = 1\n",
    "    \n",
    "    else:\n",
    "        y4[i][3] = 1\n",
    "        y2[i][1] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vascular System Data and Adjacency Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def get_p(p):\n",
    "    p = str(p)\n",
    "    if '*' in p:\n",
    "        p = re.split('\\*|\\^|\\(|\\)', p)\n",
    "        p = [float(i) for i in p if i]\n",
    "        \n",
    "        return round(p[0] * p[1]**p[2], 5)\n",
    "        \n",
    "    if '-' in p:\n",
    "        p = p.split('-')\n",
    "        p = [float(i) for i in p]\n",
    "        \n",
    "        return round(np.mean(p), 5)\n",
    "    \n",
    "    return round(float(p), 5)\n",
    "\n",
    "\n",
    "df = pd.read_excel('Таблица_графа.xlsx').iloc[:-2, :]\n",
    "df.columns = ['n', 'name', 'p', 'u', 'A']\n",
    "df.drop(['n', 'name'], axis=1, inplace=True)\n",
    "\n",
    "df['p'] = df['p'].apply(get_p)\n",
    "df['u'] = df['u'].apply(get_p)\n",
    "df['A'] = df['A'].apply(get_p)\n",
    "\n",
    "df.index += 1\n",
    "\n",
    "\"\"\"\n",
    "The dictionary with information about\n",
    "every vessel.\n",
    "\"\"\"\n",
    "Info = df.to_dict('index')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "The adjacency graph of the vascular system.\n",
    "Keys correspond to the ones of the Info graph.\n",
    "\n",
    "Keys represent vessels. \n",
    "Values: \n",
    "    first array: vessels incoming to our vessel\n",
    "    second array: vessels outgoing from our vessel\n",
    "\"\"\"\n",
    "\n",
    "Graph = {\n",
    "    1: [[],[31, 38]], 2: [[27],[58, 59, 60]], 3: [[8],[4]], 4: [[3, 80],[26]], 5: [[6, 99],[7]], 6: [[95, 97],[5]], \n",
    "    7: [[5, 101],[23]], 8: [[12, 93],[3]], 9: [[25],[10, 11]], 10: [[9],[15, 62]], 11: [[9],[54]], 12: [[16, 17],[8]], \n",
    "    13: [[15],[18, 63]], 14: [[15],[19, 65]], 15: [[10],[13, 14]], 16: [[20, 90],[12]], 17: [[21, 89],[12]], \n",
    "    18: [[13],[64]], 19: [[14],[64]], 20: [[91],[16]], 21: [[91],[17]], 22: [[69],[24]], 23: [[7],[24]], \n",
    "    24: [[22, 23],[81]], 25: [[27],[9, 61]], 26: [[4,85],[55]], 27: [[28],[2,25]], 28: [[53],[27,66]], 29: [[31],[43]], \n",
    "    30: [[31],[53,57]], 31: [[1],[29,30]], 32: [[34,35],[33]], 33: [[32],[55]], 34: [[36,79],[32]], 35: [[39,82],[32]], \n",
    "    36: [[40],[34]], 37: [[38],[42]], 38: [[1],[37, 56]], 39: [[40],[35]], 40: [[47,52],[36,39]], 42: [[37],[44,102]], \n",
    "    43: [[29],[45,104]], 44: [[42],[46]], 45: [[43],[46]], 46: [[44,45],[106]], 47: [[103],[40]], 48: [[105],[52]], \n",
    "    49: [[53],[106]], 50: [[53],[106]], 51: [[107],[52]], 52: [[48,51],[40]], 53: [[30],[28,49,50]], 54: [[11],[92]], \n",
    "    55: [[26,33],[]], 56: [[38],[67]], 57: [[30],[68]], 58: [[2],[69]], 59: [[2],[70]], 60: [[2],[71]], 61: [[25],[72]],\n",
    "    62: [[10],[73]], 63: [[13],[74]], 64: [[18,19],[75]], 65: [[14],[76]], 66: [[28],[77]], 67: [[56],[78]], \n",
    "    68: [[57],[83]], 69: [[58],[22]], 70: [[59],[100]], 71: [[60],[98]], 72: [[61],[96]], 73: [[62],[94]], \n",
    "    74: [[63],[86]], 75: [[64],[87]], 76: [[65],[88]], 77: [[66],[84]], 78: [[67],[79]], 79: [[78],[34]], 80: [[81],[4]], \n",
    "    81: [[24],[80]], 82: [[83],[35]], 83: [[68],[82]], 84: [[77],[85]], 85: [[84],[26]], 86: [[74],[90]], 87: [[75],[91]],\n",
    "    88: [[76],[89]], 89: [[88],[17]], 90: [[86],[16]], 91: [[87],[20,21]], 92: [[54],[93]], 93: [[92],[8]], \n",
    "    94: [[73],[95]], 95: [[94],[6]], 96: [[72],[97]], 97: [[96],[6]], 98: [[71],[99]], 99: [[98],[5]], 100: [[70],[101]],\n",
    "    101: [[100],[7]], 102: [[42],[103]], 103: [[102],[47]], 104: [[43],[105]], 105: [[104],[48]], 106: [[46,49,50],[107]],\n",
    "    107: [[106],[51]]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vascular System Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundary_loss(output):\n",
    "    \"\"\"\n",
    "    Checks whether the output is \n",
    "    physically possible\n",
    "    \"\"\"\n",
    "    # nothing can be negtive\n",
    "    negative = F.relu(0 - output)\n",
    "    \n",
    "    # maximum pressure = 150\n",
    "    s = int(len(output) / 3 * 2) \n",
    "    temp = output.detach().clone()\n",
    "    temp[s:] = 150\n",
    "    too_high = F.relu(output - temp)\n",
    "    \n",
    "    return torch.mean((negative + too_high)**2)\n",
    "\n",
    "\n",
    "\n",
    "def orig_cut_loss(output, x):\n",
    "    \"\"\"\n",
    "    Checks whether the outputed values\n",
    "    of the parameters of the 9 spinal veins \n",
    "    remained the same\n",
    "    \"\"\"\n",
    "    \n",
    "    index = torch.tensor([2, 3, 7, 11, 15, 16, 19, 20, 25]) # vessels indexes in the output\n",
    "    \n",
    "    A_loss = torch.mean((output[index] - x[:9])**2)\n",
    "    u_loss = torch.mean((output[index+107] - x[9:18])**2)\n",
    "    p_loss = torch.mean((output[index+214] - x[18:])**2)\n",
    "    \n",
    "    return A_loss + u_loss + p_loss\n",
    "\n",
    "\n",
    "\n",
    "def physical_equations_loss(output):\n",
    "    \"\"\"\n",
    "    Checks whether the outputs follows\n",
    "    the physical laws \n",
    "    \"\"\"\n",
    "    \n",
    "    ro = 1.055 # mean blood density\n",
    "    \n",
    "    loss1 = 0 # A1u1 = A2u2 + A3u3\n",
    "    cnt1 = 0\n",
    "    loss2 = 0 # p1 + ro u1^2 /2 = p2 + ro u2^2 /2 \n",
    "    cnt2 = 0\n",
    "    \n",
    "    for vessel in Graph.keys():\n",
    "\n",
    "        A1 = output[vessel-1]\n",
    "        u1 = output[vessel+106]\n",
    "        p1 = output[vessel+213]\n",
    "        \n",
    "        for j in range(2):\n",
    "            l1 = A1*u1\n",
    "            for i in Graph[vessel][j]:\n",
    "                l2 = p1 + 0.5 * ro * u1**2 / 2\n",
    "                \n",
    "                Ai = output[i-1]\n",
    "                ui = output[i+106]\n",
    "                pi = output[i+213]\n",
    "\n",
    "                l1 -= Ai*ui\n",
    "                l2 -= pi + 0.5 * ro * ui**2 / 2\n",
    "                \n",
    "                loss2 += l2**2\n",
    "                cnt2 += 1\n",
    "            \n",
    "            loss1 += l1**2\n",
    "            cnt1 += 1\n",
    "            \n",
    "    return loss1/cnt1 + loss2/cnt2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, n_channels, size):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.n_channels = n_channels\n",
    "        self.size = size\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=n_channels, out_channels=20, kernel_size=10),\n",
    "            nn.MaxPool2d(3, 3),\n",
    "            nn.Conv2d(in_channels=20, out_channels=16, kernel_size=5),\n",
    "            nn.AvgPool2d(2, 2)     \n",
    "        )\n",
    "        \n",
    "        '''\n",
    "        Should model 3 parameters for each of 9 \n",
    "        spinal veins.\n",
    "        '''\n",
    "        self.class_spinal = nn.Sequential(\n",
    "            nn.Linear(16*46*46, 1000),\n",
    "            nn.Linear(1000, 500),\n",
    "            nn.Linear(500, 100),\n",
    "            nn.Linear(100, 50),\n",
    "            nn.Linear(50, 27)\n",
    "        )\n",
    "        \n",
    "        self.class_params = nn.Sequential(\n",
    "            nn.Linear(27, 50),\n",
    "            nn.Linear(50, 100),\n",
    "            nn.Linear(100, 400),\n",
    "            nn.Linear(400, 321)\n",
    "        )\n",
    "        \n",
    "        self.class_disease = nn.Sequential(\n",
    "            nn.Linear(321, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 6),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.class_4 = nn.Sequential(\n",
    "            nn.Linear(6, 10),\n",
    "            nn.Linear(10, 4),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.class_cut = nn.Sequential(\n",
    "            nn.Linear(4, 10),\n",
    "            nn.Linear(10, 2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "       \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.reshape(x.shape[0], -1) # flattening\n",
    "        spinal = self.class_spinal(x)\n",
    "        system = self.class_params(spinal)\n",
    "        disease = self.class_disease(system)\n",
    "        class_4 = self.class_4(disease)\n",
    "        cut = self.class_cut(class_4)\n",
    "        \n",
    "#         return (spinal, system, torch.softmax(disease, dim=0),\n",
    "#                 torch.softmax(class_4, dim=0), torch.softmax(cut, dim=0))\n",
    "        \n",
    "        return (spinal, system, disease, class_4, cut)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X[:60]\n",
    "y6_train = y6[:60]\n",
    "y4_train = y4[:60]\n",
    "y2_train = y2[:60]\n",
    "\n",
    "x_test = X[60:]\n",
    "y6_test = y6[60:]\n",
    "y4_test = y4[60:]\n",
    "y2_test = y2[60:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(33.4218, grad_fn=<AddBackward0>)\n",
      "tensor(188.1968, grad_fn=<AddBackward0>)\n",
      "tensor(190.8452, grad_fn=<AddBackward0>)\n",
      "tensor(190.9993, grad_fn=<AddBackward0>)\n",
      "tensor(191.1252, grad_fn=<AddBackward0>)\n",
      "tensor(191.6252, grad_fn=<AddBackward0>)\n",
      "tensor(inf, grad_fn=<AddBackward0>)\n",
      "tensor(inf, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n",
      "tensor(nan, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-563-5457d9edc869>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0myi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = CNN(X[0].shape[1], X[0].shape[2])\n",
    "\n",
    "mse = nn.MSELoss()\n",
    "learning_rate = 0.1\n",
    "optim = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "yi = 0\n",
    "for pat in x_train:\n",
    "    \n",
    "    spinal, system, disease, class_4, cut = model(pat)\n",
    "    \n",
    "    loss = 0\n",
    "    loss += boundary_loss(spinal[0]) + boundary_loss(system[0])\n",
    "    print(loss)\n",
    "    loss += orig_cut_loss(system[0], spinal[0])\n",
    "    print(loss)\n",
    "    loss += physical_equations_loss(system[0])\n",
    "    print(loss)\n",
    "    loss += mse(disease[0], y6_train[yi])\n",
    "    print(loss)\n",
    "    loss += mse(class_4[0], y4_train[yi])\n",
    "    print(loss)\n",
    "    loss += mse(cut[0], y2_train[yi])\n",
    "    print(loss)\n",
    "    yi += 1\n",
    "    \n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    optim.zero_grad()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1115, -0.2747]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load marked MRI scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(file):\n",
    "    \"\"\"\n",
    "    converts the image into an array\n",
    "    \"\"\"\n",
    "    \n",
    "    image = Image.open(file)\n",
    "    return image, np.asarray(image)[:, :, :-1]\n",
    "\n",
    "\n",
    "def get_cut(file):\n",
    "    \"\"\"\n",
    "    returns the share of blue pixels\n",
    "    in percents\n",
    "    \"\"\"\n",
    "    \n",
    "    _, arr = convert(file)\n",
    "    cnt = 0\n",
    "    pat = [0, 0, 255]\n",
    "    for i in range(160, 380):\n",
    "        for j in range(100, 450):\n",
    "            if list(arr[i, j, :]) == pat:\n",
    "                cnt += 1\n",
    "                \n",
    "    return round(cnt / 512 / 512 * 100, 4)\n",
    "\n",
    "\n",
    "def get_vein(file):\n",
    "    \"\"\"\n",
    "    Determines what vein out of the 3 \n",
    "    is on the scan. \n",
    "    Returns:\n",
    "        0 - left and right external iliac veins\n",
    "        1 - four veins - left and right external\n",
    "            and internal iliac veins\n",
    "        2 - \n",
    "    \"\"\"\n",
    "\n",
    "X = []\n",
    "patients = sorted(os.listdir('Размеченные снимки МРТ'))\n",
    "print(patients)\n",
    "for patient in patients:\n",
    "    if patient != '.DS_Store':\n",
    "        print(f'Patient: {patient},', end='\\t')\n",
    "        files = os.listdir('Размеченные снимки МРТ/' + patient)\n",
    "        x = []\n",
    "        for file in sorted(files):\n",
    "            path = 'Размеченные снимки МРТ/' + patient + '/' + file\n",
    "            if 'png' in path:\n",
    "                cut = get_cut(path)\n",
    "                x.append(cut)\n",
    "        print('Done')\n",
    "        X.append(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VascularSystem(nn.Module):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        Average cuts of the two main\n",
    "        spinal veins: A_0, A_1\n",
    "    Output:\n",
    "        Average cut, velocity, and pressure\n",
    "        for 107 vessels of a human.\n",
    "        [A_i] * 107 , [u_i] * 107, [p_i] * 107.\n",
    "        A_0, A_1 = input\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(VascularSystem, self).__init__()\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(2, 100),\n",
    "            nn.Linear(100, 100),\n",
    "            nn.Linear(100, 321)\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "\n",
    "    \n",
    "X = torch.randn(100, 2)\n",
    "model = VascularSystem()\n",
    "\n",
    "optim = torch.optim.SGD(model.parameters(), lr=0.05)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optim, step_size=100, gamma=0.005)\n",
    "\n",
    "for epoch in range(1, 1001):\n",
    "    \n",
    "    pred = model(X[0])\n",
    "    \n",
    "    lp1, lp2 = physical_equations_loss(pred)\n",
    "    l = lp1 + lp2 + boundary_loss(pred) + orig_cut_loss(pred, x)\n",
    "\n",
    "    l.backward()\n",
    "\n",
    "    optim.step()\n",
    "    optim.zero_grad()\n",
    "\n",
    "#     scheduler.step()\n",
    "        \n",
    "    if epoch % 100 < 1:\n",
    "        print(f'Epoch: {epoch} \\t loss = {l:.10f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
